{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"FawltyDeps","text":"<p>FawltyDeps is a dependency checker for Python that finds undeclared and/or unused 3rd-party dependencies in your Python project. For example, it will find modules that you are <code>import</code>ing in your code, but have forgotten to declare in your <code>pyproject.toml</code> or <code>requirements.txt</code>.</p> <p></p>"},{"location":"#features","title":"Features","text":"<ul> <li>Finds undeclared dependencies: modules you are <code>import</code>ing, but forgot to declare as dependencies.</li> <li>Finds unused dependencies: dependencies you declared, but never <code>import</code>.</li> <li>Supports Python code in regular files and Jupyter notebooks.</li> <li>Supports many dependency declaration formats: <code>pyproject.toml</code>, <code>requirements.txt</code>, <code>setup.py</code>,   <code>setup.cfg</code>, <code>environment.yml</code>, and <code>pixi.toml</code>.</li> <li>Can be installed into your project as a development dependency, or run as an independent tool.</li> <li>Easily automated, e.g. as a pre-commit hook or as a CI action.</li> </ul>"},{"location":"#why-fawltydeps","title":"Why FawltyDeps?","text":"<p>Good dependency management is crucial for maintaining a healthy codebase and avoiding the \"Works on my machine\" problem. Over time, unused dependencies can accumulate, leading to bloated environments, longer installation times, and potential security risks. FawltyDeps helps keep your project installable, lean and efficient.</p> <p>We invite you to join our Discord channel! It's a great place to ask questions, share your ideas, and collaborate with other users and contributors.</p>"},{"location":"CONTRIBUTING/","title":"Contributing","text":"<p>Thank you for your interest in contributing to FawltyDeps! We welcome contributions from the community to help improve our project. Please take a moment to review this guide before you get started.</p>"},{"location":"CONTRIBUTING/#code-of-conduct","title":"Code of Conduct","text":"<p>We expect all contributors to adhere to our Code of Conduct. Please read it carefully before contributing.</p>"},{"location":"CONTRIBUTING/#getting-started","title":"Getting Started","text":""},{"location":"CONTRIBUTING/#fork-the-repository","title":"Fork the Repository","text":"<p>If you haven't already, fork the FawltyDeps repository on GitHub. This will create a copy of the project in your GitHub account.</p>"},{"location":"CONTRIBUTING/#clone-the-repository","title":"Clone the Repository","text":"<p>Clone your fork of the repository to your local machine:</p> <pre><code>git clone git@github.com:&lt;your_username&gt;/FawltyDeps.git\n</code></pre>"},{"location":"CONTRIBUTING/#set-up-your-development-environment","title":"Set Up Your Development Environment","text":""},{"location":"CONTRIBUTING/#poetry","title":"Poetry","text":"<p>The project uses Poetry. Install Poetry, and then run:</p> <pre><code>poetry install --with=dev\n</code></pre> <p>to create a virtualenv with all (development) dependencies installed.</p> <p>From there you can run:</p> <pre><code>poetry shell\n</code></pre> <p>to jump into a development shell with this virtualenv activated. Here you will have all the dependencies declared in our <code>pyproject.toml</code> installed. (Without this shell activated you will have to prefix the more specific commands below with <code>poetry run ...</code>).</p>"},{"location":"CONTRIBUTING/#nox","title":"Nox","text":"<p>We use Nox for test/workflow automation:</p> <pre><code>nox --list        # List sessions\nnox               # Run all available sessions\nnox -R            # Run all available sessions, while reusing virtualenvs (i.e. faster)\nnox -s tests      # Run unit tests on supported Python versions (that are available)\nnox -s tests-3.9  # Run unit tests on Python v3.9 (assuming it is available locally)\nnox -s integration_tests-3.11  # Run integration tests on Python 3.11\nnox -s lint       # Run linters (mypy + ruff check) on all supported Python versions\nnox -s format     # Check formatting (ruff format)\nnox -s reformat   # Fix formatting (ruff format)\n</code></pre> <p>If you want to run a command individually, the corresponding session is defined inside <code>noxfile.py</code>. For example, these commands will work:</p> <pre><code>pytest                   # Run unit tests\npytest -m integration    # Run integration tests\nmypy                     # Run static type checking\nruff check .             # Run ruff linter\nruff format .            # Run ruff formatter\n</code></pre>"},{"location":"CONTRIBUTING/#shortcut-nix","title":"Shortcut: Nix","text":"<p>We have a <code>shell.nix</code> which provides Poetry in addition to all of our supported Python versions. If you have Nix available on your machine, then running:</p> <pre><code>nix-shell\n</code></pre> <p>will put you inside a shell where the Poetry virtualenv (with all development dependencies) is activated, and all supported Python versions are available. This also provides isolation from whatever Python version(s) and packages are installed on your system.</p> <p>From there, a simple <code>nox</code> will run all tests + linters against all supported Python versions, as well as checking/formatting the code.</p>"},{"location":"CONTRIBUTING/#making-changes","title":"Making Changes","text":""},{"location":"CONTRIBUTING/#branch-naming","title":"Branch Naming","text":"<p>Create a new branch with a descriptive name for your feature or fix.</p>"},{"location":"CONTRIBUTING/#commit-messages","title":"Commit Messages","text":"<p>Write clear and concise commit messages that describe your changes.</p>"},{"location":"CONTRIBUTING/#testing","title":"Testing","text":""},{"location":"CONTRIBUTING/#running-tests-locally","title":"Running Tests Locally","text":"<p>For detailed instructions on running tests locally, please refer to the Nox section in Set Up Your Development Environment.</p>"},{"location":"CONTRIBUTING/#integration-tests","title":"Integration tests","text":"<p>In addition to comprehensive unit tests under <code>tests/</code>, we also verify FawltyDeps' behavior with integration tests which (among other things) include testing with real-world projects. To that end, we have a framework in <code>tests/test_real_projects.py</code> for downloading and unpacking tarballs of 3rd-party projects, and then running fawltydeps on them, while verifying their output. These projects, along with the expected FawltyDeps outputs, are defined in TOML files under <code>tests/real_projects</code>.</p>"},{"location":"CONTRIBUTING/#contributing-more-projects-to-the-test-suite","title":"Contributing more projects to the test suite","text":"<p>For bug reports, when a user reports that FawltyDeps does not work as it should on their project, we aim to follow this process:</p> <ul> <li>If the project is freely available, we can add a relevant version of the   project under <code>tests/real_projects</code>.</li> <li>We can then isolate the problems/issues/features and define/express them   succinctly as one or more sample projects under <code>tests/sample_projects</code>.</li> <li>We examine the issue more closely and update core logic, adding/altering unit   tests along the way.</li> </ul> <p>The resulting updates are introduced to <code>fawltydeps</code> and reflected in our expectations, first in the TOML for the sample project(s) and then finally in the <code>real_projects</code> TOML.</p> <p>If you find a project where FawltyDeps is not doing a good job, we appreciate if you add that project under <code>tests/real_projects</code>. To see how these tests work, look at the existing files in that directory.</p>"},{"location":"CONTRIBUTING/#submitting-pull-requests","title":"Submitting Pull Requests","text":"<p>When you're ready to submit your changes:</p> <ol> <li>Push your changes to your forked repository:    <code>sh    git push origin feature/your-feature-name</code></li> <li>Visit the FawltyDeps repository on GitHub.</li> <li>Click the \"New Pull Request\" button.</li> <li>Select the appropriate branch and describe your changes in the pull request. Be sure to reference any related issues.</li> </ol>"},{"location":"CONTRIBUTING/#review-process","title":"Review Process","text":"<p>Contributions to FawltyDeps go through a review process to ensure code quality and alignment with project goals. Here's how the review process works:</p> <ol> <li> <p>Submission: When you submit a pull request (PR), our automated CI/CD pipeline will run tests to check for issues and ensure that the code meets our coding standards.</p> </li> <li> <p>Code Review: A maintainer or fellow contributor will review your PR. They will provide feedback, suggest improvements, and ensure that the changes align with the project's goals and coding guidelines.</p> </li> <li> <p>Discussion: If changes or clarifications are needed, you may need to engage in discussions with reviewers to address feedback and make necessary adjustments.</p> </li> <li> <p>Approval: Once the PR meets all requirements and receives approval from one or more maintainers or contributors, it will be labeled as \"approved.\"</p> </li> <li> <p>Addressing Change Requests: If a reviewer requests changes, please make the necessary adjustments and commit the changes with a clear reference to the reviewer's comment. Use the commit hash to indicate the changes you made. The reviewer is responsible for resolving their comment once they are satisfied with the changes.</p> </li> <li> <p>Merging: A maintainer will merge the PR into the main branch. Please note that only maintainers have merge permissions.</p> </li> <li> <p>Thank You! Your contribution has now become a part of FawltyDeps. Thank you for your contribution to the project!</p> </li> </ol> <p>We appreciate your contributions and value the effort you put into improving our project. If you have any questions or need assistance during the review process, feel free to ask in the PR discussion!</p>"},{"location":"CodeDesign/","title":"Requirements","text":""},{"location":"CodeDesign/#initial-goals","title":"Initial goals","text":"<p>We want a working and usable tool that slowly adds functionality as needed. A user runs <code>fawltydeps</code> as a command line tool in their Python project and immediately gets some useful and actionable information.</p>"},{"location":"CodeDesign/#boundaries","title":"Boundaries","text":"<ul> <li>Support all current Python versions: that means all Python versions that have   a stable release, and are not yet End Of Life.<ul> <li>Currently we support running on Python v3.9 - v3.13.</li> <li>Since we no longer rely on running inside the same Python environment as the project being   analyzed, it is possible for us to support analyzing projects running on even older Python versions.</li> </ul> </li> <li>For now we support the CPython interpreter only</li> <li>OS-wise, we have concentrated on Linux. We should still run fine on   other Unix-like systems, most notably Mac. Windows remains an open question.</li> </ul>"},{"location":"CodeDesign/#code-style","title":"Code style","text":"<p>We value composability and functional style.</p> <p>We want the code to be readable, testable and maintainable. That is why we use:</p> <ul> <li>code formatter <code>ruff format</code> to unify the code style,</li> <li><code>ruff check</code> for linting</li> <li><code>mypy</code> for typecheck</li> <li><code>pytest</code> for testing   to ensure this quality.</li> </ul> <p>The code should be type-annotated, and functions should have docstrings.</p> <p>FawltyDeps searches for imports and dependencies, and to do it efficiently, generators are used in many places.</p>"},{"location":"CodeDesign/#code-review","title":"Code review","text":"<p>Read https://www.mediawiki.org/wiki/Guidelines_for_a_healthy_code_review_culture for a good introduction to the code review culture we want to foster in this project.</p>"},{"location":"CodeDesign/#tests","title":"Tests","text":"<p>FawltyDeps has unit and integration tests.</p> <p>We do not specifically aim for 100% coverage, but we do want to document the use cases via tests.</p> <p>Many tests use the following naming convention:</p> <pre><code>test_{tested_function}__{short_description}__{expected_result}\n</code></pre>"},{"location":"CodeDesign/#class-hierarchy","title":"Class hierarchy","text":"<p>Our main classes can be roughly \"layered\" as follows:</p> <p>Level 4: <code>Analysis</code> Level 3: <code>UndeclaredDependency</code> and <code>UnusedDependency</code> Level 2.5: <code>Package</code> Level 2: <code>ParsedImport</code> and <code>DeclaredDependency</code> Level 1: <code>Location</code></p> <p>Immutability (i.e. <code>frozen=True</code>) builds from the ground up, meaning that for objects at one layer to be immutable, then the objects below must also be immutable. For <code>Location</code> - at the bottom - immutability is a natural choice, and for <code>Analysis</code> - at the top - mutability makes more sense since this object is built piece by piece while going through the steps of our core logic.</p> <p>For the layers in between, level 2 is immutable at this point in time (as each object is constructed in a single operation), but this might change in the future, if we later need to extend these objects with supplemental details (e.g. when leaving the identity mapping behind). The classes at level 3 contains Lists of level 2 objects, and is therefore harder to argue that these should be immutable.</p> <p>Once a dataclass is made immutable (<code>frozen=True</code>) and it otherwise resembles a value object, it also makes sense to consider giving it <code>eq=True</code> and <code>order=True</code> as well, especially when there is a natural ordering between instances of that class.</p>"},{"location":"DesignDoc/","title":"FawltyDeps","text":"<p>A dependency checker for Python</p>"},{"location":"DesignDoc/#design-document","title":"Design document","text":"<p>Authors: Nour El Mawass, Maria Knorps</p> <p>Created: 12 Nov. 2022</p>"},{"location":"DesignDoc/#1-introduction","title":"1. Introduction","text":"<p>In Python, required packages (dependencies) are declared separately from their usage (imports within the code). There is no straightforward way to check if all imports in the code are declared as dependencies.</p> <p>It is a common problem that import statements refer to packages that were installed manually on the programmer\u2019s computer without being explicitly added to the requirements list.</p> <p>Whether it\u2019s a personal library, an application to be deployed, or a library that will be distributed for others to use, making sure that a project\u2019s imported packages are all declared as dependencies is vital for the correct packaging of that project. This will ensure both, reproducibility in other build environments and usability by other prospective users.</p> <p>This document will walk the reader through the different intricacies of Python packaging, and propose a simple modular solution to the non-declared dependencies problems. Many of the terms thrown around (such as \u201clibrary\u201d, \u201cpackage\u201d, and \u201cdependency\u201d) are overloaded, so we make sure to define and contrast each of those.</p> <p>To the best of our knowledge, there does not currently exist a solution that would effectively check if a project\u2019s declared dependencies match its imported libraries. Different aspects of the problem (e.g. extracting imported packages from Python files, generating a list of requirements, parsing transitive dependencies, validating dependencies\u2019 versions compatibility) have been explored by other contributors. We describe existing libraries and approaches, and where relevant, we indicate those that we adopted or used.</p> <p>For our prototype, we propose a command line tool. Given a Python project, this tool returns a list of unmatched imports and dependencies. A command line tool is versatile and adapted to the different usage scenarios described below. It can be both part of a manual development process or automated verification.</p> <p>A later iteration of the project could explore how to boost the usability and visibility of the implemented tool by:</p> <ul> <li>Wrapping it as a GitHub CI action</li> <li>Including it in an existing Python Linter</li> <li>Developing a VS code / Emacs extension</li> </ul> <p>It has been indicated to us by a couple of Tweag engineers (e.g. Daniel Baker) that this could be a useful tool for Python Nix packaging. We have yet to explore how that could be the case.</p>"},{"location":"DesignDoc/#scope-and-requirements","title":"Scope and requirements","text":"<p>This project\u2019s goal is to check whether a Python project has declared all the dependencies its code is importing.</p> <p>The check has different levels of assurance: a name match, package existence and package match. Proof-of-concept of FawltyDeps will address the first two.</p> <p>It is outside the scope of this work to:</p> <ul> <li>Automatically generate requirements file (as in <code>pipreqs</code> and <code>pigar</code>).</li> <li>Check that a solution to the declared requirements version exists (as poetry does).</li> <li>Complete a list of declared dependencies with transitive dependencies (as in <code>pip-compile</code>).</li> <li>Check that a declared dependency is the one that should be used (exposes not only modules, but particular functions and objects used).</li> </ul> <p>Despite initially wanting this to be a stateless checker, the intricacies of Python packaging make it impossible to verify if the dependencies are declared without gathering information from beyond the project\u2019s code base (be it the project\u2019s local environment or PyPI or GitHub repositories). The state of information in these repositories may evolve over time.</p> <p>The checker will output an error if an import does not correspond to a declared dependency (and a warning if a dependency is declared but unused).</p> <p>The remainder of this document is organized as follows. Section 2 motivates the need for the FawltyDeps library and possible usage of the library through use cases and user personas. Section 3 provides a background on the Python\u2019s imports ecosystem and may be skipped and consulted on a per-need basis. Solutions are presented, compared and contrasted in section 4. The landscape of existing work is charted in section 5 and existing contributions are compared to what FawltyDeps is attempting to achieve. Future work and enhancements are discussed in section 6.</p>"},{"location":"DesignDoc/#2-motivation-and-usage","title":"2. Motivation and usage","text":"<p>There are 2 main use cases where it is useful to check that declared dependencies are complete. Both cases involve a need to run a library in an environment different from the one it was developed in. The first case is an application that needs to be deployed in a reproducible manner. The second is a library shared with other users that also needs to be usable in different environments and in different settings.</p> <p>Expanding from this initial motivation, we present below different user personas and use cases that would benefit from using a dependency checker.</p>"},{"location":"DesignDoc/#21-user-personas","title":"2.1 User personas","text":"<ul> <li>Annie Black</li> </ul> <p>Occupation: Data Scientist \\    Goal: Share her Jupyter notebook on GitHub (with a <code>requirements.txt</code> file) for other people to use.\\    Frustrations: Non-repeatable project setup with missing dependencies.</p> <ul> <li>Jason Blue</li> </ul> <p>Occupation: Computer science student \\    Goal: Publish the Python library he implemented on PyPI.\\    Frustrations: Users complain about missing imports when installing the library.</p> <ul> <li>Patrick Magenta</li> </ul> <p>Occupation: Computational biologist \\    Goal: Contribute to an open-source project.\\    Frustrations: Non-repeatable project setup with missing dependencies.</p> <ul> <li>Deborah Yellow</li> </ul> <p>Occupation: Data engineer \\    Goal: Productionize ML pipelines developed by data scientists.\\    Frustrations: CI failing on missing dependencies.</p> <ul> <li>Andrew Cyan</li> </ul> <p>Occupation: Nix developer \\    Goal: Package python dependencies.\\    Frustrations: Inability to build package due to dependencies missing in expected files (pyproject.toml, requirements.txt, setup.py).</p> <ul> <li>Francis White</li> </ul> <p>Occupation: Software developer\u2019s experience engineer \\    Goal: Improve developers' productivity.\\    Frustrations: Developers waste time on finding errors in CI.</p>"},{"location":"DesignDoc/#22-user-stories","title":"2.2 User stories","text":"<ul> <li>Deborah wants to rerun another developer\u2019s package. She would like to know if all dependencies are in place before she sends it to a time-consuming CI.</li> <li>Patrick installed Hail[^6], which installs <code>requests</code> as a dependency. When he wrote a REST API, he forgot to add <code>requests</code> to his <code>requirements.txt</code>. The code ran correctly, but an explicit declaration of the dependency was lacking until Andrew pointed it out. Patrick would like to find those problems automatically.</li> <li>Andrew recently added testbook[^7] to <code>nixpkgs</code> and the <code>requirements.txt</code> file only listed two dependencies. When he tried to build it, there were four additional dependencies needed to run the tests. He would like all his dependencies explicitly declared.</li> <li>Francis observed that developers were using <code>pandas</code> installation from the Python packages located systemwide in Ubuntu. When the other team started working on the code, they had tests failing due to the lack of <code>pandas</code> library. Francis would like to automate checks of missing dependencies to ensure a smooth transfer of projects between teams.</li> <li>Francis observed that multiple times in the last week developers were using <code>numpy</code> in the code, but did not explicitly state this in requirements, as <code>pandas</code> installs <code>numpy</code> anyway. This led to multiple problems with the <code>numpy</code> version, which did not support some newly used features. Francis would like to have a reproducible and explicit environment declaration.</li> <li>Annie reran her package in a different environment and had to fill in missing packages signaled by import errors. Annie would like to catch problems with missing dependencies earlier and get a list of all missing packages in one run.</li> <li>Jason Publishes his package on PyPI. He wants people who use his package not to get discouraged from using it by missing dependencies. Jason wants to make sure that there is no dependencies missing.</li> </ul>"},{"location":"DesignDoc/#3-background","title":"3. Background","text":"<p>This section provides the technical background needed to understand the Python imports and dependencies system. Reading it is recommended but is not required to understand the proposed solution. You can therefore skip to Section 4 and come back to this section if needed.</p> <p>To avoid confusion and term overloading, let us start by defining some key terms. We will use the example of the <code>google_api_python_client</code>library on PyPI. This library exposes multiple packages (<code>apiclient</code>, <code>googleapiclient</code>,<code>googleapiclient/discovery_cache</code>), which can be imported in the Python code.</p> <ul> <li> <p>A package is a collection of Python modules, having an <code>__init.py__</code> file.</p> </li> <li> <p>A library exposes one or more packages (as defined in the packages field in setup.py or pyproject.toml, e.g. <code>google_api_python_client</code> exposes <code>apiclient</code>, <code>googleapiclient</code>, <code>googleapiclient/discovery_cache</code>. A library is commonly installed from PyPI.</p> </li> <li> <p>Import name is the name used to import the package in the Python source code (e.g. <code>import googleapiclient</code>).</p> </li> <li> <p>Dependency name is the name of the distributed library (e.g. <code>google_api_python_client</code>).</p> </li> <li> <p>Declared dependency is any library that is declared to be used by your code as per the methods outlined in section 3.3.</p> </li> <li> <p>Direct dependency is any external library that exposes a package that is needed as a direct result of an <code>import</code> in your code. A direct dependency that is not declared (as outlined in section 3.3) is considered an error by FawltyDeps (i.e. this is the primary thing FawltyDeps is looking for.)</p> </li> <li> <p>Transitive (indirect) dependency is a dependency of your dependency. A dependency can be both direct and transitive (e.g. your code can <code>import numpy</code> and also <code>import pandas</code>, which itself depends on <code>numpy</code>). In these cases the concerns of a direct dependency are more important (e.g. you should always declare a direct dependency even if it also happens to be an indirect dependency).</p> </li> </ul>"},{"location":"DesignDoc/#31-parsing-imports","title":"3.1 Parsing imports","text":"<p>In the Python source code, modules may be imported in different places of the code. While it\u2019s good practice to follow PEP-8 suggestions, the Python code we are to check may not be following those rules. Imports may be placed inside functions and classes. Python source code files usually have the <code>.py</code> extension. Other commonly used file types are jupyter notebooks, using <code>.ipynb</code>[^1].</p>"},{"location":"DesignDoc/#types-of-imports","title":"Types of imports","text":"<p>There are four ways to import a Python module as per the import system documentation:</p> <ul> <li>Absolute imports: <code>from packageX import Y</code></li> <li>Standard imports: <code>import packageX</code></li> <li>Aliases for imports: <code>import packageX as PX, from packageX import Y as X</code></li> <li>Function calls: <code>importlib.import_module()</code> and built-in <code>__import__()</code>.</li> </ul> <p>Imported packages may be either absolute or relative. The latter refers to the current package and starts with a leading dot, like <code>from .packageX import Y.</code></p>"},{"location":"DesignDoc/#detecting-imports-in-a-python-module","title":"Detecting imports in a Python module","text":"<p>The structure of a Python source code file can be easily obtained via the standard library Abstract Syntax Trees module. The AST library also provides an efficient way to traverse trees. Combined with standard filtering, only \u201cleaves\u201d representing imports are returned.</p> <p>Imports fall into one of four nodes in the AST (respective to a type of import):</p> <ul> <li>Absolute imports: <code>ast.Import</code></li> <li>Standard imports: <code>ast.ImportFrom</code></li> <li>Aliases for imports: <code>ast.alias</code></li> <li>Function call: <code>ast.Expr</code> with a call to either <code>__import__</code> or <code>import_module</code> function from <code>importlib</code></li> </ul> <p>Interpreting function calls as imports is not straightforward. They may use module names from other variables, functions, and external data.</p>"},{"location":"DesignDoc/#32-translating-imports-to-dependencies","title":"3.2 Translating imports to dependencies","text":"<p>Imports do not always have the same names as the dependencies they originated from. Given an argument of an import statement, Python searches for dependencies in steps[^2].</p> <p>First, it checks in <code>sys.modules</code> - a dictionary that maps Python module names to modules that have already been loaded into the environment. If the named module is not found in <code>sys.modules</code>, then Python\u2019s import protocol is invoked to find and load the module: <code>sys.meta_path</code>. This involves the usage of Python\u2019s <code>sys</code> Finders and Loaders, which may be implemented with separate strategies. For FawltyDeps, we are only concerned with \u201cfinders\u201d[^3].</p> <p>For a project that correctly runs on a local environment, it\u2019s possible to translate imports to dependencies the same way Python does, i.e. by using the \u201cfinder\u201d strategy. It is, for example, possible to follow the <code>*.dist-info/</code> directory of the library and to look at the <code>top_level.txt</code> file for exposed packages and at <code>METADATA</code> for the library name.</p> <p>In an arbitrary project, however, translating imports gathered from the source code to dependencies is a hard problem for several reasons:</p> <ol> <li>Not all libraries have the same name as the packages they expose (<code>pandas</code> exposes <code>pandas</code>, but <code>google_api_python_client</code> exposes <code>[\"apiclient\", \"googleapiclient\", \"googleapiclient/discovery_cache\"]</code>).</li> <li>Different libraries may provide import names (modules or packages) that overlap. For example, the 'google' import name may be obtained from different libraries, including <code>['google-api-core', 'googleapis-common-protos', 'protobuf', 'google-auth']</code>. This can complicate finding the appropriate library for a given import name.<code>.</code></li> <li>PyPI does not provide an API with a list of top-level packages given by the library.</li> <li>Top-level packages of a library may not be declared explicitly, but could instead be using package discovery (for projects using <code>setuptools</code>).</li> </ol> <p>Since PyPI does not readily provide this information, some libraries have attempted to solve the problem of translating imports to dependencies through a static mapping between PyPI libraries and the packages they expose (a csv file in pipreq and a database in pigar). These are shipped with the code and are not updated. This approach is discussed in more detail in the proposed solution section.</p>"},{"location":"DesignDoc/#33-extracting-a-packages-declared-dependencies","title":"3.3 Extracting a package\u2019s declared dependencies","text":""},{"location":"DesignDoc/#declaring-dependencies","title":"Declaring dependencies","text":"<p>Historically, distutils was used to ship a Python package[^4]. Now setuptools is the most common way to build a distribution package. There are other tools, like PyInstaller that builds a project into a single folder or file with all locally installed dependencies shipped with it. This is not a use case for FawltyDeps. Packaging a project with explicitly given dependencies, like with setuptools, gives the flexibility to manage and update dependencies separately. This approach makes it easier to manage and update dependencies, especially in more complex projects.</p> <p>Dependencies of a Python project may be declared in requirements (usually <code>requirements.txt</code>, but a name choice is not restricted), <code>setup.py</code>, <code>setup.cfg</code>, and then <code>pyproject.toml</code> (since PEP 518). Setup files - setup.py and setup.cfg declare dependencies under the <code>install_requires</code> and <code>extras_require</code> keywords and <code>pyproject.toml</code> generally lists dependencies under <code>dependencies</code>.</p>"},{"location":"DesignDoc/#extracting-dependencies","title":"Extracting dependencies","text":"<p>While a requirements file only lists the dependencies of a project (with eventual constraints), setup files and pyproject.toml declare other packaging configuration as well. While this is not the approach we use to parse dependnecnies, it is possible to e.g. translate pyproject.toml dependencies to requirements using poetry.</p> <p>Requirements files may have non-standard names so to extract dependencies FawltyDeps must have the option to give a list of requirements files.</p>"},{"location":"DesignDoc/#34-extracting-transitive-dependencies","title":"3.4 Extracting transitive dependencies","text":"<p>Some Python packages require other packages to be installed first (like <code>numpy</code> for <code>pandas</code>). We call them transitive dependencies. When a transitive dependency <code>A</code> is imported explicitly in the code, it becomes a direct dependency. Even though the code would work without explicitly declaring <code>A</code>, it is a better practice to do so.</p> <p>To determine the list of transitive dependencies of a library <code>myLibrary</code>, one of these commands may be used:</p> <pre><code>pip show myLibrary\nuv pip show myLibrary\npoetry show\n</code></pre> <p>Since a transitive dependency does not need to be explicitly declared, declaring transitive dependencies that are not also direct dependencies in requirements is not a common practice. Checking for these dependencies is therefore not supported by FawltyDeps.</p>"},{"location":"DesignDoc/#35-translating-dependencies-to-imports","title":"3.5 Translating dependencies to imports","text":"<p>Given a dependency, by downloading (e.g. from PyPI) and unpacking the corresponding library, it\u2019s possible to obtain the import names from the <code>top_level.txt</code> file.</p>"},{"location":"DesignDoc/#4-proposed-solution","title":"4. Proposed solution","text":""},{"location":"DesignDoc/#41-solution-outline","title":"4.1. Solution outline","text":"<p>At a first glance, the solution might look trivial once a set of imports (from the Python code) and a set of dependencies (from the packaging information) are obtained. The solution then reduces to comparing these two sets, making sure that dependencies form a superset of imports.</p> <p>While this might initially seem like a sufficient approach, directly comparing these two sets is not enough for the following reason:</p> <ol> <li>An import name is not guaranteed to be exactly equivalent to the corresponding dependency name (e.g. <code>library google-api-python-client</code> exposes package <code>apiclient</code>).</li> <li>The same library may expose different packages, which then correspond to different import names (e.g. <code>library google-api-python-client</code> apart from <code>apiclient</code>exposes <code>googleapiclient</code> and <code>googleapiclient/discovery_cache</code>).</li> </ol> <p>In other words, given two one-element sets of imports and dependencies, {<code>apiclient</code>} and {<code>google-api-python-client</code>} respectively, originating from the same Python project, there\u2019s no static way to compare these sets.</p> <p>This is further complicated by the following observations:</p> <ol> <li>The same import name can map to various library names representing different packages (e.g. on PyPI, both <code>retina-face</code> and <code>retinaface</code> have the same import name <code>retinaface</code>). The import-to-dependency relation is one-to-many.</li> <li>Some imports might not have their corresponding dependencies explicitly declared because they are transitive dependencies (e.g. <code>numpy</code> is a prerequisite of <code>pandas</code>).</li> </ol> <p>The analysis above shows that these sets should be mapped to the same domain before a comparison is possible. One possible mapping would be to map one set to the domain of the other, i.e. map import names to dependency names or vice versa.</p> <p>The solution would then consist of 4 main modules (see the diagram below):</p> <ol> <li>Extract imports used in the code.</li> <li>Extract declared dependencies.</li> <li>Map imports and dependencies to the same domain.</li> <li>Compare mapped imports and dependencies.</li> </ol> <p></p> <p>[1] Solution diagram; link to Lucid Charts; you have to log in to read and edit.</p>"},{"location":"DesignDoc/#42-possible-domain-mappings","title":"4.2. Possible domain mappings","text":"<p>We discuss in this section, three possible imports and dependencies mappings, differing in complexity and having each its advantages and limitations:</p> <ol> <li>Identity mapping.</li> <li>Mapping import names to library names.</li> <li>Mapping library names to import names.</li> </ol>"},{"location":"DesignDoc/#421-identity-mapping","title":"4.2.1 Identity mapping","text":"<p>As the name implies, this assumes import names are equivalent to library names. It allows for static checking, and compared to the more complex mappings detailed below, is exceedingly straightforward.</p> <p>Despite lacking empirical evidence on how many libraries (e.g. on PyPI) use the library name as an import name, we expect this mapping to be useful as a lightweight check that covers the majority of libraries.</p> <p>The major limitation of the identity mapping strategy is that it cannot compare an import <code>x</code> to a dependency <code>y</code> if those are not identically named. Therefore, the moment the imports set and the dependencies set differ, we would need to map one set to the domain of the other.</p> <p>Furthermore, even when the sets are identical, there is no guarantee that dependencies are correctly declared. As we have discussed earlier, an import <code>x</code> does not necessarily map to a dependency <code>x</code>.</p> <p>It is possible to go one step further and check that the declared dependencies exist (on e.g. PyPI). But while this would probably guard against declaring non-existent libraries, it would still not solve the following situation (as no mapping between the import and dependency domains is performed). Suppose you use <code>import madeup</code> in your code, and you assume the dependency name to be <code>madeup</code> as well so that\u2019s what you provide in <code>requirements.txt</code>. As it turns out, <code>madeup</code>, the dependency, exists, but does not expose a package <code>madeup</code>. What you needed to declare was <code>pymadeup</code>, which effectively exposes import name <code>madeup</code>. The checker would not flag the dependency as missing, since no mapping has been done and it was assumed the dependency is indeed the one declared.</p> <p>An extension to this is relaxed equality[^5], where punctuation and conversions between snake_case and kebab-case are allowed. This is a cheap extension (no package downloading and unpacking is required) that can extend the usability of identity mapping.</p>"},{"location":"DesignDoc/#422-import-to-dependency-mapping","title":"4.2.2 Import to dependency mapping","text":"<p>Mapping an import name to a dependency name is based on the premise that it would be easy to map an import (module or package) to a dependency (library).</p> <p>Suppose you have the import <code>madeup</code> and that you\u2019d like to find the corresponding library name. This is often done via search engines and manual inspection of matching results.</p> <p>To simplify the problem, let\u2019s further suppose that this is a PyPI library. One would expect that PyPI has a mapping from import names (which are essentially names of packages exposed by a library) to a library name. This is unfortunately not a valid assumption as such a mapping does not exist.</p> <p>PyPI offers some features that can be exploited to construct the mapping in an offline or online manner. There\u2019s the search feature, which is a free text search on the information publicly available on the library\u2019s PyPI web page. The library information available via the metadata API does not contain the exposed package's information (import names). Thus the only way to obtain that information seems to be by downloading and unpacking the library from PyPI.</p> <p>Note that in both cases, the mapping is limited to libraries available on PyPI and would not be able to map an import to a non-PyPI library.</p> <p>Furthermore, the check would now become a verification that for every import, the intersection between the mapping of that import to the dependency space and the declared dependencies is non empty..</p> <p>Offline mapping</p> <p>One could imagine iterating through all libraries in PyPI, and for each library, downloading, unpacking, and extracting the list of package names. Once a database is constructed, this would allow instant mapping from the package name to the library name (and vice versa). But this solution has two main limitations. First, the constructed database would need to be shipped with the code or available via an API, which adds either a heavy file or the need to communicate with an external service. Second, periodic maintenance and updates for the database are needed so it does not become stale.</p> <p>Online mapping</p> <p>The closest one could get to finding a package (i.e. import) name in PyPI is via its free text search. As stated above, this search is not done over the structured library information but over the information available on the PyPI web page of the library. As this search would understandably return many unrelated results, post-processing on these results is needed. This would consist of downloading and unpacking each library to extract the packages' names. While this might seem like an improvement over the whole PyPI mapping described above, keep in mind that some search terms (e.g. google) may return tens of thousands of records.</p> <p>A limitation is that the import name is not guaranteed to be on the library\u2019s web page so the search might not return the wanted library.</p> <p>Another potential downside is that it's not uncommon to run CI in a heavily restricted network environment (e.g. using a URL allowlist). Getting such allow lists updated can, in some organizations, be pretty arduous. As such, the ability to run FawltyDeps entirely offline will likely lower the barrier to entry significantly.</p> <p>Conclusion</p> <p>Static offline mapping has been done in libraries such as pipreqs and pigar, and is usually distributed with the library. As previously stated, this has the disadvantage of leading to stale mappings. A possible solution is to provide an API offering a frequently updated version of that PyPI mapping. This in itself would be a useful contribution and could be used by libraries attempting to automatically generate a project\u2019s requirements. It is, however, an instance of solving problem B (mapping import names to dependency names) in order to solve problem A (ensuring all imports are declared). And, as we show in the next section, might be rendered unnecessary by mapping in the opposite direction.</p> <p>Another possible way to limit the scope of the mapping is when all dependencies are installed in the local environment in which FawltyDeps would run. The checker can, in this case, search locally installed libraries in order to create the needed mapping. A similar solution is provided as an option in <code>pipreqs</code>.</p>"},{"location":"DesignDoc/#423-dependency-to-import-mapping","title":"4.2.3 Dependency to import mapping","text":"<p>The previous section focused on mapping imports to dependencies. That can be a useful exercise if the goal is to automatically generate a Python project\u2019s dependencies (e.g. the requirements.txt file). The goal of this project however is to check if the declared dependencies match the used imports.</p> <p>Mapping dependencies to imports is conceptually more aligned with that goal. And while that can still be easily reconstructed from any full PyPI import to dependency mapping, having a full mapping is unnecessary. Given a set of declared dependencies, by downloading and unpacking each library, as described in the previous section, it\u2019s possible to obtain the import names (from e.g the top-level or the dist-info directories) in an on-demand fashion. Only dependencies declared in the project are downloaded and unpacked. The test would then become to verify that the mapped dependencies form a superset of extracted imports.</p> <p>This solution has the advantage of not being limited to PyPI libraries. Like the online mapping discussed above, however, it also requires access to the repositories of the project\u2019s dependencies (e.g. PyPI, Github, ..)</p> <p>As in the previous solution, it is equally possible to limit this solution to searching in the local environment. This can also be made the default option, after which the tool would expand the search to public repositories.</p>"},{"location":"DesignDoc/#5-related-work","title":"5. Related work","text":""},{"location":"DesignDoc/#51-linters","title":"5.1 Linters","text":"<p>A perfect place to have a dependency checker add-on would be a linter. The most popular: <code>flake8</code> and <code>pylint</code> do not provide this functionality.</p>"},{"location":"DesignDoc/#52-translating-imports-to-requirementtxt","title":"5.2 Translating imports to requirement.txt","text":"<p>Several libraries generate requirements based on imports in Python source code. The two most visible in the community are pipreqs and pigar. In the context of Python Dependency Checker, they cover parsing imports and mapping them to PyPI libraries.</p> <p><code>pipreqs</code> is more popular than <code>pigar</code>, as can be seen in the Github star history graph [2], but it has not been regularly maintained for the last year and a half. It currently has many open and unsolved issues. <code>pipreqs</code> is also much simpler than pigar in terms of source code and functionality.</p> <p> [2] History of GitHub stars of pigar and pipreqs libraries</p> <p>\\ Both libraries use AST to inspect Python source code, but <code>pigar</code>\u2019s implementation covers more use cases. <code>pipreqs</code> parses the simplest imports only (the ones that can be found in AST under <code>Import</code> or <code>ImportFrom</code> class) while <code>pigar</code> parses <code>exec</code>, <code>importlib</code> expressions, and more.</p> <p>Both libraries rely on a mapping of PyPI libraries to exposed packages. In <code>pipreqs</code>, this is done with a CSV file, which is seldom updated lately. In <code>pigar</code>, the mapping is more elaborate - it consists of an SQLite database and an additional PyPI package check, performed when the <code>pigar</code> script is run to generate the requirements.txt file (in case there was a breaking change between versions or a package was deleted). To check a package, <code>pigar</code> downloads it from PyPI in a packed form and peeks at the top_level.txt file to see the list of exposed packages. To assign a package version, <code>pipreqs</code> checks if a library is installed locally, and if so, it uses the version from the metadata of installation. If not, then it infers the library name from a static file mapping and posts a request to PyPI with that library name to get a package version.</p> <p>Libraries like <code>pigar</code> and <code>pipreqs</code> that automatically populate requirements files by translating imports to dependencies suffer from a major problem. Given a set of imports, the generated set of dependencies may be large and include many irrelevant libraries. These libraries are included just because they expose a package with the same name as an imported package.</p> <p>The import to dependencies translation (generating requirements.txt) depends on the chosen solution. Pigar downloads all possible candidates for a dependency package and it is a time-consuming process. Neither of the discussed libraries has a caching mechanism.</p>"},{"location":"DesignDoc/#53-dependency-management-libraries","title":"5.3 Dependency management libraries","text":"<p>Both Poetry and pip-tools are package management libraries that offer complimentary features to what FawltyDeps proposes to achieve. We discuss below Poetry\u2019s functionality in more details.</p> <p>Poetry is a popular dependency management and packaging library for Python. Its features are centered around:</p> <ul> <li>the pyproject.toml file, in which custom Poetry fields are defined.</li> <li>a corresponding poetry.lock file which \u201clocks\u201d versions of the project\u2019s dependencies to ensure reproducibility.</li> </ul> <p>Poetry manages installation of packages and offers its own virtual environments. It has a dependency specification syntax coupled with a powerful dependency resolving mechanism. It can \u201csync\u201d an environment with declared dependencies to ensure that no extra libraries are installed, which can prevent using a library in the development environment without proper declaration.</p> <p>While Poetry has a <code>check</code> command, this command only validates the structure of the pyproject.toml file, and does not ensure that all the imported dependencies are declared. Poetry seems to limit itself to the scope of defining and managing dependencies and doesn\u2019t in fact seem to do any code introspection.</p> <p>Poetry commands and our proposed tool\u2019s functionality complement each other, and it\u2019s possible to consider having FawltyDeps as a Poetry plugin in the future.</p>"},{"location":"DesignDoc/#6-future-work","title":"6. Future work","text":"<ul> <li>Ensuring from the usage of the library in the code that the declared library is the needed one.</li> <li>Transitive dependencies:</li> <li>Completing requirements.txt with used but undeclared transitive dependencies.</li> <li>Downgrading the error on a missing transitive dependency to a warning (e.g. x is a dependency of declared library y but is not explicitly declared).</li> <li>Execution time</li> <li>Implement caching mechanism.</li> <li>Smart mapping (identity, then translation)</li> </ul>"},{"location":"DesignDoc/#references","title":"References","text":""},{"location":"DesignDoc/#python-documentation","title":"Python documentation","text":"<ol> <li>PEP 8 \u2013 Style Guide for Python Code: https://peps.python.org/pep-0008/#imports.</li> <li>The import system: https://docs.python.org/3/reference/import.html#the-import-system.</li> <li>Abstract syntax tree: https://docs.python.org/3.10/library/ast.html.</li> <li>Distutils: https://docs.python.org/3/library/distutils.html#module-distutils.</li> <li>PIP: https://pip.pypa.io/en/stable/reference/requirements-file-format/#requirements-file-format.</li> <li>PEP 518 - Specifying Minimum Build System Requirements for Python Projects: https://peps.python.org/pep-0518.</li> <li>PEP 621 \u2013 Storing project metadata in pyproject.toml: https://peps.python.org/pep-0621.</li> </ol>"},{"location":"DesignDoc/#libraries","title":"Libraries","text":"<ol> <li>SetupTools, packaging Python projects: https://setuptools.pypa.io/en/latest/.</li> <li>Pireqs, generate requirements.txt based on imports: https://github.com/bndr/pipreqs.</li> <li>Pigar, generate requirements.txt based on imports: https://github.com/damnever/pigar.</li> <li>PyInstaller, angle folder static Python packaging: https://pyinstaller.org/en/stable/operating-mode.html#.</li> <li>Poetry, Python packaging, and dependency management: https://python-poetry.org/.</li> <li>Poetry, a plugin to export locked packages: https://github.com/python-poetry/poetry-plugin-export.</li> <li>Pip-tools, a set of command-line tools to maintain pip-based packages: https://github.com/jazzband/pip-tools.</li> </ol>"},{"location":"DesignDoc/#other-sources","title":"Other sources","text":"<ol> <li>Caremad.io, a blog post about setup.py and requirements.txt: setup.py vs requirements.txt \u00b7 caremad.</li> <li>Towardsdatascience.com, a blog post about setup.py and requirements.txt: requirements.txt vs setup.py in Python.</li> </ol>"},{"location":"DesignDoc/#notes","title":"Notes","text":"<p>[^1]: Notebooks may be converted to Python script with nbconvert - command line tool and library. [^2]: See the import paths search Python documentation. [^3]: See an example of usage of Python\u2019s ModuleFinder. [^4]: distutils is deprecated and will be removed in Python 3.12. [^5]: Suggested by Thomas Bagrel. [^6]: Hail, cloud-native genomic data frames, and batch computing: https://hail.is/. [^7]: Testbook is a unit testing framework extension for testing code in Jupyter Notebooks: https://github.com/nteract/testbook/.</p>"},{"location":"FAQ/","title":"FAQ","text":""},{"location":"FAQ/#when-do-i-need-to-use-base-dir","title":"When do I need to use <code>--base-dir</code>?","text":"<p>When FawltyDeps analyzes <code>import</code> statements in your code, it needs to correctly differentiate between 1st-party imports (i.e. modules that are found inside your project) and 3rd-party imports (and that indicate real 3rd-party dependencies). FawltyDeps needs a base directory where it can find these 1st-party imports, and by default it uses directory information passed on the command line. For example:</p> <ul> <li><code>fawltydeps my_project/</code> will look for Python code under <code>my_project/</code>, and   will also use <code>my_project/</code> as the base directory for 1st-party imports.</li> <li>Likewise, <code>fawltydeps --code=my_project/</code> will do the same.</li> <li><code>fawltydeps --code=projectA/ --code=projectB/</code> will use <code>projectA/</code> as the   base directory for code under <code>projectA/</code>, and <code>projectB/</code> as the   base directory for code under <code>projectB/</code>.</li> <li>If you pass only filenames, no directories, e.g.   <code>fawltydeps foo/main.py lib/bar.py</code>, then FawltyDeps will default to using the   current directory (<code>./</code>) as the base directory. This is fine as long as the   current directory is an appropriate base directory for your project, for   example when <code>foo/main.py</code> imports <code>lib/bar.py</code> with a statement like   <code>from lib import bar</code>.</li> </ul> <p>There are some scenarios, however, where the base directory is not correctly deduced by FawltyDeps, and where you would use <code>--base-dir</code> to adjust this (and without otherwise changing what code FawltyDeps is looking at).</p> <ul> <li>If you only pass filenames, no directories, and the current directory is not   an appropriate base directory. In the above filename-only example, if   <code>foo/main.py</code> instead uses <code>import bar</code> (say your project is run in a manner   where <code>lib/</code> is on the <code>$PYTHONPATH</code>), then this <code>bar</code> import will not be   found in the current directory, and you would need to pass <code>--base-dir=lib/</code>   in order to bring FawltyDeps up to speed.</li> <li>If your project structure is more complex -- e.g. if you are running   FawltyDeps on a subproject + libs within a larger monorepo, and you need to   identify which directory is the appropriate base for imports, e.g.   <code>fawltydeps subproject/main/ subproject/lib/ --base-dir=subproject/</code></li> </ul> <p>Note that <code>--base-dir</code> changes the base directory for all code that is analyzed by FawltyDeps. For example, when you run <code>fawltydeps --code=my_project/ --code=other_file.py --base-dir=lib/</code>, both the code found under <code>my_project/</code> and the code in <code>other_file.py</code> will be analyzed with the assumption that 1st-party imports will be found under <code>lib/</code>. (Without <code>--base-dir</code>, the implicit base directories would be <code>my_project/</code> for code found under there, and <code>./</code> for code in <code>other_file.py</code>.)</p>"},{"location":"FAQ/#why-does-fawltydeps-fail-to-match-sklearn-with-scikit-learn","title":"Why does FawltyDeps fail to match <code>sklearn</code> with <code>scikit-learn</code>?","text":"<p>There are cases, where FawltyDeps may not match imports and obviously related dependencies, like <code>sklearn</code> and <code>scikit-learn</code>. It will report <code>sklearn</code> as undeclared and <code>scikit-learn</code> as an unused dependency.</p> <p>This is very much related to the above question. <code>scikit-learn</code> is an example of a package that exposes a different import name: <code>sklearn</code>. When <code>scikit-learn</code> is not found in the Python environment(s) used by FawltyDeps, then FawltyDeps is unable to make the connection between these two names.</p> <p>To solve this problem, make sure that <code>scikit-learn</code> is installed in a Python environment that belongs to your project. Alternatively, you can use the <code>--pyenv</code> option to point at a Python environment where <code>scikit-learn</code> and your other dependencies are installed.</p>"},{"location":"FAQ/#my-project-is-using-python-version-before-v39-can-i-still-use-fawltydeps","title":"My project is using Python version before v3.9, can I still use FawltyDeps?","text":"<p>Yes! Even though FawltyDeps itself runs on Python &gt;=v3.9, we try to support analyzing projects that run on any version of Python 3.</p> <p>As explained in the previous two questions, FawltyDeps itself does not need to run inside the same Python environment as your project and its dependencies.</p> <p>You can instead install FawltyDeps using a newer Python version (e.g. via uvx or pipx). Then run FawltyDeps from inside your project directory. If your project has an embedded Python environment (e.g. under <code>.venv/</code>) then FawltyDeps should automatically find it and use it to analyze your project dependencies. Alternatively, you can always use <code>--pyenv</code> to point FawltyDeps to where your dependencies are installed.</p> <p>Currently the lowest Python version that your project can use (and still be analyzed by FawltyDeps) is determined by our use of the <code>ast</code> module in the Python standard library: As long as your project's Python syntax is compatible with the Python version that FawltyDeps runs on, you should be fine. If you run into problems with older Python syntax (e.g. using <code>async</code> or <code>await</code> as variable names), please open an issue, and we'll look into extending our support further.</p> <p>A final resort can be to downgrade to an older version of FawltyDeps that is compatible with the Python version used in your project. Currently, these are the Python versions we have dropped support for, and the latest FawltyDeps release to support that version:</p> <ul> <li>Python v3.7 last supported in FawltyDeps v0.18.</li> <li>Python v3.8 last supported in FawltyDeps v0.19.</li> </ul>"},{"location":"FAQ/#does-fawltydeps-need-to-run-in-the-same-python-environment-as-my-project","title":"Does FawltyDeps need to run in the same Python environment as my project?","text":"<p>No (not since FawltyDeps v0.11). FawltyDeps should be able to automatically find your project dependencies when they are installed in a Python environment that exists within your project. If your project dependencies are installed elsewhere, you can point FawltyDeps in their direction with <code>--pyenv</code>, as explained in the section on Python environment mapping.</p> <p>See also the next question for more details.</p>"},{"location":"FAQ/#why-does-fawltydeps-need-a-python-environment-with-my-project-dependencies","title":"Why does FawltyDeps need a Python environment with my project dependencies?","text":"<p>The reason why FawltyDeps need to find your project dependencies somewhere is that the core logic of FawltyDeps needs to match <code>import</code> statements in your code with dependencies declared in your project configuration. This seems straightforward for many packages: for example you <code>pip install requests</code> and then you can <code>import requests</code> in your code. However, this mapping from the name you install to the name you <code>import</code> is not always self-evident:</p> <ul> <li>There are sometimes differences between the package name that you   declare as a dependency, and the <code>import</code> name it provides. For example, you   depend on <code>PyYAML</code>, but you <code>import yaml</code>.</li> <li>A dependency can expose more than one import name. For example the   <code>setuptools</code> package exposes three <code>import</code>able packages: <code>_distutils_hack</code>,   <code>pkg_resources</code>, and <code>setuptools</code>. So when you <code>import pkg_resources</code>,   FawltyDeps need to figure out that this corresponds to the <code>setuptools</code>   dependency.</li> </ul> <p>To solve this, FawltyDeps looks at the packages installed in your Python environment to correctly map dependencies (package names) into the imports that they provide. This is:</p> <ul> <li>any Python environment found via the <code>--pyenv</code> option,</li> <li>or if <code>--pyenv</code> is not given: any Python environment found within your   project (<code>basepath</code> or the current directory).</li> <li>In addition, FawltyDeps will use the current Python environment,   i.e. the one in which FawltyDeps itself is running.</li> </ul> <p>As a final resort, when an installed package is not found for a declared dependency, the identity mapping that FawltyDeps falls back to will still do a good job for the majority of dependencies where the import name is indeed identical to the package name that you depend on.</p>"},{"location":"configuration/","title":"Configuration","text":""},{"location":"configuration/#configuration-file","title":"Configuration file","text":"<p>You can use a <code>[tool.fawltydeps]</code> section in <code>pyproject.toml</code> to configure the default behavior of FawltyDeps. Here's a fairly comprehensive example:</p> <pre><code>[tool.fawltydeps]\ncode = [\"myproject\"]  # Only search for imports under ./myproject\ndeps = [\"pyproject.toml\"]  # Only look for declared dependencies here\nignore_unused = [\"black\"]  # We use `black`, but we don't intend to import it\noutput_format = \"human_detailed\"  # Detailed report by default\n</code></pre> <p>Here is a complete list of configuration directives we support:</p> <ul> <li><code>actions</code>: A list of one or more of these actions to perform: <code>list_imports</code>,   <code>list_deps</code>, <code>check_undeclared</code>, <code>check_unused</code>. The default behavior   corresponds to <code>actions = [\"check_undeclared\", \"check_unused\"]</code>.</li> <li><code>output_format</code>: Which output format to use by default. One of <code>human_summary</code>,   <code>human_detailed</code>, or <code>json</code>.   The default corresponds to <code>output_format = \"human_summary\"</code>.</li> <li><code>code</code>: Files or directories containing the code to parse for import statements.   Defaults to the current directory, i.e. like <code>code = [\".\"]</code>.</li> <li><code>deps</code>: Files or directories containing the declared dependencies.   Defaults to the current directory, i.e. like <code>deps = [\".\"]</code>.</li> <li><code>pyenvs</code>: Where to look for Python environments (directories like <code>.venv</code>,   <code>__pypackages__</code>, or similar) to be used for resolving project dependencies   into provided import names. Defaults to looking for Python environments under   the current directory, i.e. like <code>pyenvs = [\".\"]</code>.</li> <li><code>ignore_undeclared</code>: A list of specific dependencies to ignore when reporting   undeclared dependencies, for example: <code>[\"some_module\", \"some_other_module\"]</code>.   Simple <code>*</code>-wildcards are supported. The default is the empty list:   <code>ignore_undeclared = []</code>.</li> <li><code>ignore_unused</code>: A list of specific dependencies to ignore when reporting   unused dependencies, for example: <code>[\"black\", \"mypy\", \"some_other_module\"]</code>.   Simple <code>*</code>-wildcards are supported, so e.g. <code>\"pytest-*\"</code> can be used to ignore   many pytest plugins. If <code>ignore_unused</code> is left unconfigured, it defaults to a   list of common development tools (see the <code>DEFAULT_IGNORE_UNUSED</code> variable in   <code>fawltydeps/settings.py</code>   for the complete list). Once you specify it, however, your list will replace   the default list.</li> <li><code>deps_parser_choice</code>: Manually select which format to use for parsing   declared dependencies. Must be one of <code>\"requirements.txt\"</code>, <code>\"setup.py\"</code>,   <code>\"setup.cfg\"</code>, <code>\"pyproject.toml\"</code>, <code>\"pixi.toml\"</code>, <code>\"environment.yml\"</code>, or   leave it unset (i.e. the default) for auto-detection (based on filename).</li> <li><code>install-deps</code>: Automatically install Python dependencies gathered with   FawltyDeps into a temporary virtual environment. This will use <code>uv</code> or <code>pip</code>   to download and install packages from PyPI by default.</li> <li><code>exclude</code>: File/directory patterns to exclude/ignore when looking for code   (imports), dependency declarations and/or Python environments. Defaults to   <code>exclude = [\".*\"]</code>, meaning that hidden/dot paths are excluded from traversal.</li> <li><code>exclude_from</code>: Files (following the .gitignore format) containing exclude   patterns to use when looking for code (imports), dependency declarations   and/or Python environments. Defaults to an empty list: <code>exclude_from = []</code>.</li> <li><code>verbosity</code>: An integer controlling the default log level of FawltyDeps:<ul> <li><code>-2</code>: Only <code>CRITICAL</code>-level log messages are shown.</li> <li><code>-1</code>: <code>ERROR</code>-level log messages and above are shown.</li> <li><code>0</code>: <code>WARNING</code>-level log messages and above are shown. This is the default.</li> <li><code>1</code>: <code>INFO</code>-level log messages and above are shown.</li> <li><code>2</code>: All log messages (including <code>DEBUG</code>) are shown.</li> </ul> </li> <li><code>custom_mapping_file</code>: Paths to files containing user-defined mapping.   Expected file format is defined in the User-defined mapping section.</li> <li><code>[tool.fawltydeps.custom_mapping]</code>: Section in the configuration, under which a custom mapping   can be added. Expected format is described in the User-defined mapping section.</li> </ul>"},{"location":"configuration/#environment-variables","title":"Environment variables","text":"<p>In addition to configuring FawltyDeps via <code>pyproject.toml</code> as show above, you may also pass the above configuration directives via the environment, using a <code>fawltydeps_</code> prefix. For example, to enable JSON output via the environment, set <code>fawltydeps_output_format=json</code> in FawltyDeps' environment.</p>"},{"location":"configuration/#configuration-cascade","title":"Configuration cascade","text":"<ul> <li>Command-line options take precedence, and override corresponding settings   passed via the environment or <code>pyproject.toml</code>.</li> <li>Environment variables override corresponding settings from <code>pyproject.toml</code>.</li> <li>Configuration in <code>pyproject.toml</code> override only the ultimate hardcoded defaults.</li> <li>The ultimate defaults when no customizations takes place are hardcoded inside   FawltyDeps, and are documented above.</li> </ul>"},{"location":"explanation/","title":"Explanation","text":""},{"location":"explanation/#key-concepts","title":"Key Concepts","text":"<ul> <li>undeclared dependency:   a package that's used (in particular, <code>import</code>ed) by a project and which lacks a corresponding declaration to ensure that it's available.   For example, you <code>import numpy</code>, but you've forgotten to include <code>numpy</code> in your <code>requirements.txt</code>.   Pragmatically, this means the project is prone to runtime errors.</li> <li>unused dependency:   a package that's declared as necessary for a project but which is never used by project code.   For example, you have <code>numpy</code> listed in your <code>requirements.txt</code>, but you never actually <code>import numpy</code>.   Pragmatically, this means that project installation may consume more space than needed and will be more likely to break with future software releases; in short, these are costs paid for no benefit.</li> </ul>"},{"location":"explanation/#resolving-dependencies","title":"Resolving dependencies","text":"<p>When FawltyDeps looks for undeclared and unused dependencies, it needs to match <code>import</code> statements in your code with corresponding package dependencies declared in your project configuration.</p> <p>To solve this, FawltyDeps uses a sequence of resolvers (aka. mapping strategies) to determine which Python packages provide which import names. For more details, check the FawltyDeps mapping strategy blog post. The diagram below shows the dependencies' flow through the sequence of mappings supported by FawltyDeps (each of which is introduced in the following subsections):</p> <ul> <li>Local Python environment mapping</li> <li>Mapping via temporarily installed packages</li> <li>Identity mapping</li> <li>User-defined mapping</li> </ul> <p></p> <p>The priority of each of these mappings, together with their default values and customization options are summarized in the table below:</p> Priority Mapping strategy Options 1 User-defined mapping Provide a custom mapping in TOML format via <code>--custom-mapping-file</code> or a <code>[tool.fawltydeps.custom_mapping]</code> section in <code>pyproject.toml</code>.  Default: No custom mapping 2 Mapping from installed packages found inside project Point to one or more environments with <code>--pyenv</code>.Default: auto-discovery of Python environments under the project\u2019s basepath. 3 Mapping from packages installed in <code>sys.path</code> Active by default. No CLI option. This finds packages installed in the Python environment in which FawltyDeps itself runs. 4a Mapping via temporary installation of packages Activated with the <code>--install-deps</code> option. 4b Identity mapping Active by default. Deactivated when <code>--install-deps</code> is used."},{"location":"explanation/#local-python-environment-mapping","title":"Local Python environment mapping","text":"<p>Local Python environment mapping refers to using packages already installed in local Python environments on your system to resolve dependencies into the imports they expose. This leverages the functionality provided by the excellent <code>importlib_metadata</code> library.</p> <p>You can use the <code>--pyenv</code> option (or the <code>pyenvs</code> configuration directive) to point FawltyDeps at one [or more] specific Python environment(s) located within your project or elsewhere. For example:</p> <pre><code>fawltydeps --code my_package/ --deps pyproject.toml --pyenv /path/to/project/venv\n</code></pre> <p>This will tell FawltyDeps:</p> <ul> <li>to look for <code>import</code> statements in the <code>my_package/</code> directory,</li> <li>to parse dependencies from <code>pyprojects.toml</code>, and</li> <li>to use the Python environment at <code>/path/to/project/venv</code> to map dependency names in   <code>pyproject.toml</code> into import names used in your code under <code>my_package/</code></li> </ul> <p>If <code>--pyenv</code> is not used, FawltyDeps will look for Python environments (virtualenvs or similar directories like <code>.venv</code> or <code>__pypackages__</code>.) inside your project (i.e. under <code>basepath</code>, if given, or the current directory).</p> <p>You can use <code>--pyenv</code> multiple times to have FawltyDeps look for packages in multiple Python environments. In this case (or when multiple Python environments are found inside your project) FawltyDeps will use the union (superset) of all imports provided by all matching packages across those Python environments as valid import names for that dependency.</p>"},{"location":"explanation/#current-python-environment","title":"Current Python environment","text":"<p>In addition to the local Python environments found above, FawltyDeps will also look at your current Python environment, i.e. the environment in which FawltyDeps itself is installed. This works well when you, for example, <code>pip install fawltydeps</code> into the same virtualenv as your project dependencies, no matter where this virtualenv may be located.</p>"},{"location":"explanation/#identity-mapping","title":"Identity mapping","text":"<p>When unable to find an installed package that corresponds to a declared dependency either via a user-defined mapping or local  Python environments, FawltyDeps will fall back to one of two strategies. \"Identity mapping\", which we present in this section is the default fallback strategy. We discuss the other strategy in the next subsection.</p> <p>Identity mapping relies on the simplistic assumption that the dependency provides a single import of the same name, i.e. it will expect that when you depend on <code>some_package</code>, then that should correspond to <code>import some_package</code> statements in your code.</p> <p>This assumption is correct for many packages and it allows FawltyDeps to produce results (albeit sometimes inaccurate ones) when the current Python environment does not contain all of your declared dependencies.</p> <p>To ensure correctness, however, refer to the next subsection outlining the other fallback strategy.</p>"},{"location":"explanation/#mapping-by-temporarily-installing-packages","title":"Mapping by temporarily installing packages","text":"<p>Your local Python environments might not always have all your project's dependencies installed. Assuming that you don\u2019t want to go through the bother of installing packages manually, and you also don't want to rely on the inaccurate identity mapping as your fallback strategy, you can use the <code>--install-deps</code> option. This will automatically install missing dependencies (from PyPI, by default) into a temporary virtualenv, and allow FawltyDeps to use this to come up with the correct mapping.</p> <p>Since this is a potentially expensive strategy (e.g. downloading packages from PyPI), we have chosen to hide it behind the <code>--install-deps</code> command-line option. If you want to always enable this option, you can set the corresponding <code>install_deps</code> configuration variable to <code>true</code> in the <code>[tool.fawltydeps]</code> section of your <code>pyproject.toml</code>.</p> <p>FawltyDeps will use <code>uv</code> by default to temporarily install missing dependencies. If <code>uv</code> not available, <code>pip</code> will be used instead. If you want to ensure that the faster <code>uv</code> is available, you can install <code>fawltydeps</code> with the <code>uv</code> extra (e.g. <code>pip install fawltydeps[uv]</code>).</p> <p>To further customize how this automatic installation is done (e.g. if you need to use a different package index), you can use environment variables to alter <code>uv</code>'s or <code>pip</code>\u2019s  behavior.</p> <p>Note that we\u2019re never guaranteed to be able to resolve all dependencies with this method: For example, there could be a typo in your <code>requirements.txt</code> that means a dependency will never be found on PyPI, or there could be other circumstances (e.g. network issues or restrictions in your CI environment) that prevent this strategy from working at all. In this case, FawltyDeps will throw an error and abort.</p>"},{"location":"explanation/#user-defined-mapping","title":"User-defined mapping","text":"<p>Sometimes Python dependencies are imported using a different name than the package name used in the <code>import</code> statement. Some Python packages might have hyphens in their dependency names used by package managers, but underscores in their import  names, for example.</p> <p>We provide a custom mapping functionality to users wishing to take control over the way FawltyDeps resolves dependencies. You may define your own mapping of dependency names to import names, by providing a TOML file like this:</p> <pre><code>langchain-core = [\"langchain_core\"]\nmultiple-modules = [\"module1\", \"module2\"]\nmy-package = [\"mpkg\"]\npython-dotenv = [\"dotenv\"]\nscikit-learn = [\"sklearn\"]\n</code></pre> <p>The package name of the dependency is on the left-hand side of the <code>=</code>, and the import name(s) are on the right-hand side. You can provide multiple import names for a single dependency.</p> <p>To use your mapping, run:</p> <pre><code>fawltydeps --custom-mapping-file my_mapping.toml\n</code></pre> <p>FawltyDeps will parse your <code>my_mapping.toml</code> file and use the extracted mapping for matching dependencies to imports.</p> <p>You may also place the custom mapping in the <code>pyproject.toml</code> file of your project, inside a <code>[tool.fawltydeps.custom_mapping]</code> section, like this:</p> <pre><code>[tool.fawltydeps.custom_mapping]\nlangchain-core = [\"langchain_core\"]\nmultiple-modules = [\"module1\", \"module2\"]\nmy-package = [\"mpkg\"]\npython-dotenv = [\"dotenv\"]\nscikit-learn = [\"sklearn\"]\n</code></pre> <p>The provided mapping can be complete or partial. When a dependency is not present in the given mapping, FawltyDeps will continue to resolve it using the sequence of resolvers illustrated in the diagram above.</p> <p>Caution when using your mapping is advised: As illustrated in the diagram, the user-defined mapping takes precedence over the other resolvers documented above. For example, if the mapping file has some stale/incorrect mapping entries, they will not be resolved by the Python environment resolver (which is usually more accurate).</p>"},{"location":"how_to_guides/","title":"How-to guides","text":""},{"location":"how_to_guides/#general","title":"General","text":""},{"location":"how_to_guides/#handle-undeclared-dependencies","title":"Handle undeclared dependencies","text":"<p>I run <code>fawltydeps</code> and get some undeclared dependencies. What can I do with it?</p> <p>You can run a detailed report to see the exact location (file and line number) in which the undeclared dependencies were imported:</p> <pre><code>fawltydeps --detailed\n</code></pre> <p>If your Python environment happens to have packages installed that provide any of these import names, then the report will also suggest these package names. (This is often what happens if you have <code>pip install</code>ed a dependency, but forgot to declare it properly.)</p> <p>Go through each undeclared dependency, and consider how to resolve it, typically in one of these ways:</p> <ul> <li>A true undeclared dependency is fixed by declaring it, e.g. adding it to   your <code>pyproject.toml</code> or similar.</li> <li>Sometimes the code might be <code>import</code>ing a module without actually using it,   then you might be able to simply remove the <code>import</code> statement altogether.</li> <li>If you disagree with FawltyDeps' classification, you can always use   <code>--ignore-undeclared</code> to silence the error. If you're sure this dependency   should not have been reported by FawltyDeps, please file a bug report to make   us aware of the issue.</li> </ul>"},{"location":"how_to_guides/#configuration-run","title":"Configuration &amp; run","text":""},{"location":"how_to_guides/#ignore-development-tools","title":"Ignore development tools","text":"<p>How not to display tools like <code>black</code> and <code>pylint</code> in unused dependencies?</p> <p>By default, all packages declared as dependencies by your project are included in the FawltyDeps analysis. This includes tools that are typically not meant to be <code>import</code>ed, but rather meant to be run by, say, in a pre-commit hook or a CI script. In such cases you may use either:</p> <pre><code>fawltydeps --ignore-unused black pylint\n</code></pre> <p>or add an equivalent directive to the FawltyDeps configuration in your <code>pyproject.toml</code> (see below).</p>"},{"location":"how_to_guides/#store-fawltydeps-options-in-a-configuration-file","title":"Store <code>fawltydeps</code> options in a configuration file.","text":"<p>You can run:</p> <pre><code>fawltydeps --generate-toml-config\n</code></pre> <p>to generate a <code>[tool.fawltydeps]</code> section with the current configuration that you can then directly copy into your <code>pyproject.toml</code>. Options that have their default value are commented in this output, so you have quickly see where your settings differ from the FawltyDeps defaults.</p> <p>This also works together with other command line options, so for example in the previous question, you could add <code>--generate-toml-config</code> to the command line (i.e. run <code>fawltydeps --ignore-unused black pylint --generate-toml-config</code>), to get this:</p> <pre><code>[tool.fawltydeps]\n# Default options are commented...\nignore_unused = [\"black\", \"pylint\"]\n</code></pre>"},{"location":"how_to_guides/#specific-use-cases","title":"Specific use cases","text":""},{"location":"how_to_guides/#fawltydeps-with-a-monorepo","title":"FawltyDeps with a monorepo.","text":"<p>Running <code>fawltydeps</code> without arguments at the root of a monorepo will most likely not give you a useful result: it will collect dependencies and import statements from across the entire monorepo. The produced report may be overwhelming and at the same time not granular enough.</p> <p>Instead, you should run FawltyDeps for each package separately. This collects dependencies and import statements for one package at a time.</p> <p>Having:</p> <pre><code>\u251c lib1\n| \u251c pyproject.toml\n| \u251c ....\n\u251c lib2\n| \u251c pyproject.toml\n| \u251c ....\n</code></pre> <p>run for each <code>libX</code>:</p> <pre><code>fawltydeps libX\n</code></pre>"},{"location":"how_to_guides/#passing-python-code-via-standard-input","title":"Passing Python code via standard input.","text":"<p>The <code>--code</code> argument accepts a single hyphen (<code>-</code>) as a special value meaning that code should be read from standard input. When using this you may pipe or redirect your Python code into FawltyDeps like this:</p> <pre><code>cat some/source/of/python/code | fawltydeps --code -\n# or\nfawltydeps --code - &lt; some/source/of/python/code\n</code></pre> <p>You can also use this directly in the terminal to e.g. have FawltyDeps analyze some Python code that is in your clipboard:</p> <pre><code>fawltydeps --code -\n# FawltyDeps waits for code on stdin; paste from your clipboard,\n# then press Ctrl+D to signal EOF (end-of-file).\n</code></pre>"},{"location":"how_to_guides/#integrations","title":"Integrations","text":""},{"location":"how_to_guides/#pre-commit-hook","title":"Pre-commit hook","text":"<p>Assuming that you already use the pre-commit tool, you can add something like this to your project's <code>.pre-commit-config.yaml</code>:</p> <pre><code>repos:\n  - repo: https://github.com/tweag/FawltyDeps\n    rev: v0.20.0\n    hooks:\n      - id: check-undeclared\n      - id: check-unused\n</code></pre>"},{"location":"how_to_guides/#github-action","title":"GitHub action","text":"<p>FawltyDeps works well when run as a lint step in continuous integration systems.</p> <p>Please see tweag/FawltyDeps-action for a GitHub Action that implements FawltyDeps linting. You can also get the FawltyDeps GitHub Action from the Actions Marketplace.</p>"},{"location":"installation/","title":"Installation","text":""},{"location":"installation/#installation","title":"Installation","text":""},{"location":"installation/#requirements","title":"Requirements","text":"<ul> <li>Python 3.9 or higher</li> </ul>"},{"location":"installation/#installation_1","title":"Installation","text":"<p>FawltyDeps is distributed with PyPI, so any way you install PyPI dependencies is supported, for example:</p> <ul> <li><code>pip install fawltydeps</code></li> <li>Use your project manager tool to install it as a development dependency, for example:<ul> <li><code>uv add --dev fawltydeps</code></li> <li><code>poetry add --group=dev fawltydeps</code></li> <li><code>pdm add -dG dev fawltydeps</code></li> <li>manually add <code>fawltydeps</code> to you <code>dev-requirements.txt</code></li> </ul> </li> </ul> <p>You can also install FawltyDeps as a stand-alone tool to make it generally available:</p> <ul> <li>With uv: <code>uv tool install fawltydeps</code></li> <li>With pipx: <code>pipx install fawltydeps</code></li> </ul>"},{"location":"usage/","title":"Usage","text":"<p>To check the project in the current directory run:</p> <pre><code>fawltydeps\n</code></pre> <p>This will find imports in all the Python code under the current directory, extract dependencies declared by your project, and then report undeclared and unused dependencies.</p>"},{"location":"usage/#available-actions","title":"Available Actions","text":"<p>FawltyDeps provides the following options for controlling what actions to perform. Only one of these can be used at a time:</p> <ul> <li><code>--check</code>: Report both undeclared and unused dependencies</li> <li><code>--check-undeclared</code>: Report only undeclared dependencies</li> <li><code>--check-unused</code>: Report only unused dependencies</li> <li><code>--list-imports</code>: List third-party imports extracted from the project</li> <li><code>--list-deps</code>: List declared dependencies extracted from the project</li> <li><code>--list-sources</code>: List files/directories from which imports, declared   dependencies and installed packages would be extracted</li> </ul> <p>When none of these are specified, the default action is <code>--check</code>.</p>"},{"location":"usage/#where-to-find-code-and-dependency-declarations","title":"Where to find code and dependency declarations","text":"<p>By default, FawltyDeps will look for Python code (<code>*.py</code> and <code>*.ipynb</code>) and dependency declarations (see list of supported files below) under the current directory. If you want FawltyDeps to look elsewhere, you can pass one or more directories (aka <code>search_paths</code>) as positional arguments:</p> <pre><code>fawltydeps my_project/\n</code></pre> <p>If you want to separately declare the source of the code and the source of the dependencies, you may use the <code>--code</code> and <code>--deps</code> options documented in the next section. In short, giving the <code>search_paths</code> positional argument is equivalent to passing both the <code>--code</code> and the <code>--deps</code> options, like this:</p> <pre><code>fawltydeps --code my_project/ --deps my_project/\n</code></pre>"},{"location":"usage/#where-to-find-python-code","title":"Where to find Python code","text":"<p>The <code>--code</code> option tells FawltyDeps where to find the Python code to parse for <code>import</code> statements. You can pass any number of these:</p> <ul> <li>a single file: Either a Python file (<code>*.py</code>) or a Jupyter Notebook (<code>*.ipynb</code>)</li> <li>a directory: FawltyDeps will find all Python files and Jupyter notebooks under this directory.</li> <li><code>-</code>: Passing a single dash (<code>--code=-</code>) tells FawltyDeps to read Python code   from stdin.</li> </ul> <p>If no <code>--code</code> option is passed, FawltyDeps will find all Python code under the <code>search_paths</code>, if given, or the current directory (i.e. same as <code>--code=.</code>). To include both code from stdin (<code>import foo</code>) and a file path (<code>file.py</code>), use:</p> <pre><code>echo \"import foo\" | fawltydeps --list-imports --code - file.py\n</code></pre> <p>At any time, if you want to see where FawltyDeps is looking for Python code, you can use the <code>--list-sources --detailed</code> options.</p>"},{"location":"usage/#correctly-identifying-1st-vs-3rd-party-imports","title":"Correctly identifying 1st- vs. 3rd-party imports","text":"<p>In order for FawltyDeps to tell whether an <code>import</code> statement in your code refers or a 1st-party module (i.e. part of this project), or a 3rd-party dependency, it needs a base directory, i.e. a directory where 1st-party imports can be found.</p> <p>By default, FawltyDeps deduces this from the passed <code>--code</code> (or <code>search_paths</code>) arguments, but for complex project structures, you might have to use the <code>--base-dir=&lt;dir&gt;</code> option to tell FawltyDeps which directory to use. This option may be used once to determine the base directory for all code being analyzed.</p>"},{"location":"usage/#where-to-find-declared-dependencies","title":"Where to find declared dependencies","text":"<p>The <code>--deps</code> option tells FawltyDeps where to look for your project's declared dependencies. A number of file formats are supported:</p> <ul> <li><code>*requirements*.txt</code> and <code>*requirements*.in</code></li> <li><code>pyproject.toml</code> (following PEP 621 or Poetry conventions)</li> <li><code>setup.py</code> (only limited support for simple files with a single <code>setup()</code>   call and no computation involved for setting the <code>install_requires</code> and   <code>extras_require</code> arguments)</li> <li><code>setup.cfg</code></li> <li><code>pixi.toml</code></li> <li><code>environment.yml</code></li> </ul> <p>The <code>--deps</code> option accepts a space-separated list of files or directories. Each file will be parsed for declared dependencies; each directory will be searched, parsing all of the supported files (see the above list) found within. You would typically want to pass individual files, if you want to be explicit about where to find the declared dependencies.</p> <p>If no <code>--deps</code> option is passed, FawltyDeps will look for the above files under the <code>search_paths</code>, if given, or the current directory (i.e. same as <code>--deps .</code>).</p>"},{"location":"usage/#how-to-match-import-statements-with-declared-dependencies","title":"How to match <code>import</code> statements with declared dependencies","text":"<p>When FawltyDeps analyzes undeclared and unused dependencies, it needs to match <code>import</code> statements in your code with corresponding package dependencies declared in your project configuration. We support the following options to help this process:</p> <ul> <li><code>--pyenv</code>: Where to search for Python environments (e.g. virtualenvs) that have project dependencies installed. Finding installed dependencies is the best way to correctly match import names  and declared dependencies. If this is not given, the project directories will be searched for Python environments.</li> <li><code>--custom-mapping-file</code>: A TOML file containing mapping of dependencies to import names defined by the user. When provided, this mapping takes precedence over looking through installed packages for a match. This is a power user feature for when you want full control of how FawltyDeps matches import names and package names.</li> <li><code>--install-deps</code>: Allow FawltyDeps to auto-install declared dependencies into a separate temporary virtualenv to discover the imports they expose. This is potentially expensive, but it allows FawltyDeps to provide a good analysis when there is no existing Python environment with project dependencies installed.</li> </ul> <p>For more details about the process of matching <code>import</code> statements to declared dependencies, please see the Resolving dependencies section in Explanation.</p>"},{"location":"usage/#excluding-paths","title":"Excluding paths","text":"<p>If you want FawltyDeps to exclude parts of your source tree when loooking for code, dependency declarations, or Python environments, then you can use the <code>--exclude</code> option to specify path patterns to exclude, e.g. the following command will skip everything under <code>tests/</code>:</p> <pre><code>fawltydeps --exclude tests/\n</code></pre> <p>The format of the exclude patterns is the same as used by <code>.gitignore</code> files, see here for a full description.</p> <p>When the <code>--exclude</code> option is not specified, its default value is <code>\".*\"</code>, which matches all paths that start with a dot (<code>.</code>), aka. \"hidden\" paths. In the above example, if you want to exclude both hidden paths, and everything under <code>tests/</code>, then instead use:</p> <pre><code>fawltydeps --exclude tests/ \".*\"\n</code></pre> <p>(The extra quotes here are needed to prevent the shell from interpreting and replacing the <code>*</code> wildcard.)</p> <p>You can also point to exclude patterns stored in a file, with the <code>--exclude-from</code> option. E.g. to read exclude patterns from <code>./my_excludes.txt</code>:</p> <pre><code>fawltydeps --exclude-from my_excludes.txt\n</code></pre> <p>Exclude patterns have lower priority than any paths you pass directly on the command line, e.g. in this command:</p> <pre><code>fawltydeps --code my_file.py --exclude my_file.py\n</code></pre> <p>the <code>--code</code> options \"wins\" (i.e. imports in <code>my_file.py</code> will be found); the <code>--exclude</code> option only takes affect when traversing directories to look for more files. E.g. use this to find code inside <code>my_dir</code>, but skip Jupyter notebooks:</p> <pre><code>fawltydeps --code my_dir --exclude \"*.ipynb\"\n</code></pre>"},{"location":"usage/#ignoring-irrelevant-results","title":"Ignoring irrelevant results","text":"<p>There may be <code>import</code> statements in your code that should not be considered an undeclared dependency. This might happen if you for example do a conditional <code>import</code> with a <code>try: ... except ImportError: ...</code> block (or similar). FawltyDeps is not able to recognize whether these dependencies should have been declared or not, but you can ask for them to be ignored with the <code>--ignore-undeclared</code> option, for example: <code>--ignore-undeclared some_module some_other_module</code></p> <p>Conversely, there may be dependencies that you have declared without intending to <code>import</code> them. This is often the case for developer tools like Black or Mypy that are part of your project's development environment. We've introduced a <code>DEFAULT_IGNORE_UNUSED</code> list, which includes various categories of commonly used development tools and dependencies. FawltyDeps can automatically ignore these dependencies when checking for unused imports. For the complete list, please see the <code>DEFAULT_IGNORE_UNUSED</code> variable in the <code>fawltydeps/settings.py</code> file in the repository. If you have additional dependencies that you want to exclude from the check for unused imports, you can use the <code>--ignore-unused</code> option to customize the ignore list. By providing your own list of dependencies with this option, you can effectively overwrite the default list. For example: <code>--ignore-unused black mypy some_other_module</code></p> <p>Both <code>--ignore-undeclared</code> and <code>--ignore-unused</code> support use of simple <code>*</code>-wildcards to ignore multiple dependencies, for example <code>--ignore-unused types-*</code> to ignore type stubs dependencies, or <code>--ignore-unused *pre-commit*</code> to ignore the pre-commit tool and associated addons.</p>"},{"location":"usage/#output-formats","title":"Output formats","text":"<p>The default output from FawltyDeps is a summary outlining the relevant dependencies found (according to the selected actions). However you can also ask for more information from FawltyDeps:</p> <ul> <li><code>--summary</code>: Default (human-readable) summary output</li> <li><code>--detailed</code>: Longer (human-readable) output that includes the location of   the relevant dependencies. For undeclared dependencies, it also includes   names of installed packages that happen to provide this dependency.</li> <li><code>--json</code>: Verbose JSON-formatted output for other tools to consume and   process further.</li> </ul> <p>Only one of these options can be used at a time.</p>"},{"location":"usage/#more-help","title":"More help","text":"<p>Run <code>fawltydeps --help</code> to get the full list of available options.</p>"}]}